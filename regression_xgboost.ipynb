{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3a38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b783093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id  label\n",
      "0   sample697.npy      7\n",
      "1    sample54.npy     81\n",
      "2  sample2270.npy      4\n",
      "3  sample1401.npy     99\n",
      "4  sample1901.npy     43\n",
      "\n",
      "总样本数: 2177\n",
      "\n",
      "尝试加载图像文件: ./ot\\sample697.npy\n",
      "图像文件加载成功！\n",
      "图像数据类型: uint16\n",
      "图像数据形状 (shape): (128, 128, 125)\n",
      "警告：图像形状 (128, 128, 125) 与预期的 (高度, 宽度, 100) 不完全一致，请检查。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_file_path = 'train.csv' \n",
    "train_df = pd.read_csv(csv_file_path)\n",
    "print(train_df.head())\n",
    "print(f\"\\n总样本数: {len(train_df)}\")\n",
    "\n",
    "\n",
    "image_dir = './ot'\n",
    "if not os.path.isdir(image_dir):\n",
    "    print(f\"警告：图像目录 '{image_dir}' 不存在。请确保路径正确，并且包含.npy文件。\")\n",
    "\n",
    "# 3. 尝试加载第一个 .npy 文件来查看其结构\n",
    "if len(train_df) > 0 and os.path.isdir(image_dir):\n",
    "    first_image_name = train_df.loc[0, 'id'] # 获取第一个样本的 .npy 文件名\n",
    "    first_image_path = os.path.join(image_dir, first_image_name)\n",
    "\n",
    "    try:\n",
    "        print(f\"\\n尝试加载图像文件: {first_image_path}\")\n",
    "        image_data = np.load(first_image_path)\n",
    "        print(\"图像文件加载成功！\")\n",
    "        print(f\"图像数据类型: {image_data.dtype}\")\n",
    "        print(f\"图像数据形状 (shape): {image_data.shape}\")\n",
    "        # 根据我们之前的讨论，我们期望形状类似于 (高度, 宽度, 100)\n",
    "        if len(image_data.shape) == 3 and image_data.shape[2] == 100:\n",
    "            print(\"图像的波段数量为100，符合预期。\")\n",
    "        else:\n",
    "            print(f\"警告：图像形状 {image_data.shape} 与预期的 (高度, 宽度, 100) 不完全一致，请检查。\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：未找到图像文件 {first_image_path}。请确保 'image_dir' 设置正确且文件存在。\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载图像文件 {first_image_path} 时发生错误: {e}\")\n",
    "else:\n",
    "    if len(train_df) == 0:\n",
    "        print(\"train_df 为空，无法加载图像。\")\n",
    "    # 如果目录不存在，上面已经给过警告了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee45fd0",
   "metadata": {},
   "source": [
    "一点发现：跟数据集描述的不同，训练集的2217条数据和545条数据中都有不符合预期的（125，57，125）大小的数据，我们需要进行填充。考虑到我们的目标是预测病害百分比，以及我们选用的特征（各波段平均反射率）具体的措施： 在您的 `extract_features` 函数中，当遇到宽度为57的图像时，可以对每个波段（经过125选100波段之后）应用 反射填充或者是均值填充来进行两侧填充，将其宽度扩展到128。然后再计算这100个（已填充到128宽度）波段各自的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4981b0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始为所有 2177 个训练样本提取特征...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 934/2177 [00:06<00:08, 147.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误：处理文件 ./ot\\sample2451.npy 时发生: cannot reshape array of size 1785856 into shape (128,128,125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2177/2177 [00:15<00:00, 142.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "特征提取完成！\n",
      "注意：共有 1 个文件因形状问题或处理错误被跳过。\n",
      "X_train 的形状: (2176, 100)\n",
      "y_train 的形状: (2176,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TARGET_HEIGHT = 128\n",
    "TARGET_WIDTH = 128\n",
    "ORIGINAL_BANDS = 125 # 原始文件中的波段数\n",
    "\n",
    "# 3. 定义波段选择的切片 (选择索引10到109的波段，共100个)\n",
    "band_selection_slice = slice(10, 110)\n",
    "NUM_SELECTED_BANDS = 100 # band_selection_slice.stop - band_selection_slice.start\n",
    "\n",
    "def process_and_extract_features(image_path, target_height, target_width, band_slice):\n",
    "    \"\"\"\n",
    "    加载高光谱图像，对需要填充的图像进行填充，选择波段，并计算平均反射率。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_data = np.load(image_path) # 期望形状 (h, w, 125)\n",
    "        \n",
    "        current_height, current_width, current_bands = image_data.shape\n",
    "\n",
    "        # 检查基本维度是否符合预期（高度和原始波段数）\n",
    "        if current_height != target_height or current_bands != ORIGINAL_BANDS:\n",
    "            print(f\"警告：文件 {os.path.basename(image_path)} 的形状 ({current_height}, {current_width}, {current_bands}) \"\n",
    "                  f\"与预期的高度 {target_height} 或原始波段数 {ORIGINAL_BANDS} 不符。将跳过此文件。\")\n",
    "            return None\n",
    "\n",
    "        # 如果宽度不是目标宽度，则进行填充 (例如，原始宽度为57，目标为128)\n",
    "        if current_width != target_width:\n",
    "            if current_width < target_width: # 只处理宽度不足的情况\n",
    "                pad_total = target_width - current_width\n",
    "                pad_left = pad_total // 2\n",
    "                pad_right = pad_total - pad_left\n",
    "                \n",
    "                # 对宽度维度进行填充，其他维度不填充\n",
    "                # ((上下填充), (左右填充), (通道前后填充))\n",
    "                padding_config = ((0, 0), (pad_left, pad_right), (0, 0))\n",
    "                \n",
    "                # 使用 'reflect' 模式填充\n",
    "                # 您可以将 'reflect' 更改为 'symmetric' 来测试不同效果\n",
    "                padded_image_data = np.pad(image_data, padding_config, mode='reflect')\n",
    "                # print(f\"填充文件 {os.path.basename(image_path)} from {image_data.shape} to {padded_image_data.shape}\")\n",
    "            else: # 如果图像宽度大于目标宽度，可以选择裁剪或跳过\n",
    "                print(f\"警告：文件 {os.path.basename(image_path)} 的宽度 {current_width} 大于目标宽度 {target_width}。将跳过此文件。\")\n",
    "                return None\n",
    "        else:\n",
    "            padded_image_data = image_data # 不需要填充\n",
    "\n",
    "        # 波段选择 (此时 padded_image_data 的形状应为 [target_height, target_width, ORIGINAL_BANDS])\n",
    "        selected_bands_data = padded_image_data[:, :, band_slice] # 形状变为 [h, w, NUM_SELECTED_BANDS]\n",
    "        \n",
    "        # 计算每个选定波段的平均反射率\n",
    "        mean_reflectance = np.mean(selected_bands_data, axis=(0, 1)) # 形状变为 [NUM_SELECTED_BANDS,]\n",
    "        \n",
    "        return mean_reflectance\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：处理时未找到文件 {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"错误：处理文件 {image_path} 时发生: {e}\")\n",
    "        return None\n",
    "    \n",
    "def process_and_extract_features_mean_pad(image_path, target_height, target_width, original_bands_count, band_slice):\n",
    "    \"\"\"\n",
    "    加载高光谱图像，对需要填充的图像使用其各波段自身均值进行填充，\n",
    "    然后选择波段，并计算平均反射率。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_data = np.load(image_path) # 期望形状 (h, w, original_bands_count)\n",
    "        \n",
    "        current_height, current_width, current_bands = image_data.shape\n",
    "\n",
    "        if current_height != target_height or current_bands != original_bands_count:\n",
    "            print(f\"警告：文件 {os.path.basename(image_path)} 的形状 ({current_height}, {current_width}, {current_bands}) \"\n",
    "                  f\"与预期的高度 {target_height} 或原始波段数 {original_bands_count} 不符。将跳过此文件。\")\n",
    "            return None\n",
    "\n",
    "        processed_image_data = np.zeros((target_height, target_width, original_bands_count), dtype=image_data.dtype)\n",
    "\n",
    "        if current_width != target_width:\n",
    "            if current_width < target_width: # 只处理宽度不足的情况\n",
    "                pad_total = target_width - current_width\n",
    "                pad_left = pad_total // 2\n",
    "                pad_right = pad_total - pad_left\n",
    "                \n",
    "                padding_config_2d = ((0, 0), (pad_left, pad_right)) # 只针对H, W维度中的W\n",
    "\n",
    "                # 逐个波段进行均值填充\n",
    "                for i in range(original_bands_count):\n",
    "                    band_original_data = image_data[:, :, i] # 单个波段 (H, current_W)\n",
    "                    band_mean = np.mean(band_original_data)   # 计算该波段原始有效区域的均值\n",
    "                    \n",
    "                    # 使用计算得到的均值进行常数填充\n",
    "                    padded_band = np.pad(band_original_data, padding_config_2d, mode='constant', constant_values=band_mean)\n",
    "                    processed_image_data[:, :, i] = padded_band\n",
    "                \n",
    "                # print(f\"均值填充文件 {os.path.basename(image_path)} from {image_data.shape} to {processed_image_data.shape}\")\n",
    "\n",
    "            else: # 如果图像宽度大于目标宽度\n",
    "                print(f\"警告：文件 {os.path.basename(image_path)} 的宽度 {current_width} 大于目标宽度 {target_width}。将跳过此文件。\")\n",
    "                return None\n",
    "        else: # 宽度已经是目标宽度，无需填充\n",
    "            processed_image_data = image_data\n",
    "        \n",
    "        # 波段选择 (此时 processed_image_data 的形状应为 [target_height, target_width, original_bands_count])\n",
    "        selected_bands_data = processed_image_data[:, :, band_slice] # 形状变为 [h, w, NUM_SELECTED_BANDS]\n",
    "        \n",
    "        # 计算每个选定波段的平均反射率\n",
    "        mean_reflectance = np.mean(selected_bands_data, axis=(0, 1)) # 形状变为 [NUM_SELECTED_BANDS,]\n",
    "        \n",
    "        return mean_reflectance\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：处理时未找到文件 {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"错误：处理文件 {image_path} 时发生: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# 准备存储特征和标签的列表\n",
    "X_list = []\n",
    "y_list = []\n",
    "skipped_files_count = 0\n",
    "\n",
    "print(f\"\\n开始为所有 {len(train_df)} 个训练样本提取特征...\")\n",
    "for index, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    image_name = row['id']\n",
    "    label = row['label']\n",
    "    current_image_path = os.path.join(image_dir, image_name)\n",
    "    \n",
    "    features = process_and_extract_features(current_image_path, \n",
    "                                            TARGET_HEIGHT, \n",
    "                                            TARGET_WIDTH, \n",
    "                                            band_selection_slice)\n",
    "    \n",
    "    if features is not None and features.shape == (NUM_SELECTED_BANDS,):\n",
    "        X_list.append(features)\n",
    "        y_list.append(label)\n",
    "    else:\n",
    "        # print(f\"警告：未能为样本 {image_name} 提取有效特征，已跳过。\")\n",
    "        skipped_files_count += 1\n",
    "\n",
    "\n",
    "# 将列表转换为 NumPy 数组\n",
    "X_train = np.array(X_list)\n",
    "y_train = np.array(y_list)\n",
    "\n",
    "print(f\"\\n特征提取完成！\")\n",
    "if skipped_files_count > 0:\n",
    "    print(f\"注意：共有 {skipped_files_count} 个文件因形状问题或处理错误被跳过。\")\n",
    "print(f\"X_train 的形状: {X_train.shape}\") # 应该为 (成功处理的样本数, 100)\n",
    "print(f\"y_train 的形状: {y_train.shape}\") # 应该为 (成功处理的样本数,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a520ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28dfe2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据划分完成！\n",
      "新的训练集 X_train_cv 的形状: (1740, 100)\n",
      "新的训练集标签 y_train_cv 的形状: (1740,)\n",
      "验证集 X_val_cv 的形状: (436, 100)\n",
      "验证集标签 y_val_cv 的形状: (436,)\n"
     ]
    }
   ],
   "source": [
    "# 检查 X_train 和 y_train 是否有数据\n",
    "if X_train.shape[0] > 0 and y_train.shape[0] > 0 and X_train.shape[0] == y_train.shape[0]:\n",
    "    # 进行数据划分\n",
    "    # test_size=0.2 表示验证集占20%\n",
    "    # random_state 是一个种子，确保每次划分结果一致，方便复现\n",
    "    X_train_cv, X_val_cv, y_train_cv, y_val_cv = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42 # 您可以选择任何整数作为随机种子\n",
    "    )\n",
    "\n",
    "    print(\"\\n数据划分完成！\")\n",
    "    print(f\"新的训练集 X_train_cv 的形状: {X_train_cv.shape}\")\n",
    "    print(f\"新的训练集标签 y_train_cv 的形状: {y_train_cv.shape}\")\n",
    "    print(f\"验证集 X_val_cv 的形状: {X_val_cv.shape}\")\n",
    "    print(f\"验证集标签 y_val_cv 的形状: {y_val_cv.shape}\")\n",
    "\n",
    "    # 2176 * 0.8 = 1740.8 (约 1740 或 1741)\n",
    "    # 2176 * 0.2 = 435.2 (约 435 或 436)\n",
    "    # scikit-learn 会自动处理取整\n",
    "\n",
    "else:\n",
    "    print(\"错误：X_train 或 y_train 为空或样本数量不匹配，无法进行数据划分。\")\n",
    "    print(\"请确保之前的特征提取步骤已成功生成 X_train 和 y_train。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b761698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您当前使用的 XGBoost 版本是: 2.0.3\n",
      "Help on method fit in module xgboost.sklearn:\n",
      "\n",
      "fit(X: Any, y: Any, *, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, eval_metric: Union[str, Sequence[str], Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]], NoneType] = None, early_stopping_rounds: Optional[int] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, ForwardRef('XGBModel'), str, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None, callbacks: Optional[Sequence[xgboost.callback.TrainingCallback]] = None) -> 'XGBModel' method of xgboost.sklearn.XGBRegressor instance\n",
      "    Fit gradient boosting model.\n",
      "\n",
      "    Note that calling ``fit()`` multiple times will cause the model object to be\n",
      "    re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      "    pass ``xgb_model`` argument.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    X :\n",
      "        Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "\n",
      "        When the ``tree_method`` is set to ``hist``, internally, the\n",
      "        :py:class:`QuantileDMatrix` will be used instead of the :py:class:`DMatrix`\n",
      "        for conserving memory. However, this has performance implications when the\n",
      "        device of input data is not matched with algorithm. For instance, if the\n",
      "        input is a numpy array on CPU but ``cuda`` is used for training, then the\n",
      "        data is first processed on CPU then transferred to GPU.\n",
      "    y :\n",
      "        Labels\n",
      "    sample_weight :\n",
      "        instance weights\n",
      "    base_margin :\n",
      "        global bias for each instance.\n",
      "    eval_set :\n",
      "        A list of (X, y) tuple pairs to use as validation sets, for which\n",
      "        metrics will be computed.\n",
      "        Validation metrics will help us track the performance of the model.\n",
      "\n",
      "    eval_metric : str, list of str, or callable, optional\n",
      "\n",
      "        .. deprecated:: 1.6.0\n",
      "\n",
      "        Use `eval_metric` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      "\n",
      "    early_stopping_rounds : int\n",
      "\n",
      "        .. deprecated:: 1.6.0\n",
      "\n",
      "        Use `early_stopping_rounds` in :py:meth:`__init__` or :py:meth:`set_params`\n",
      "        instead.\n",
      "    verbose :\n",
      "        If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      "        measured on the validation set is printed to stdout at each boosting stage.\n",
      "        If `verbose` is an integer, the evaluation metric is printed at each\n",
      "        `verbose` boosting stage. The last boosting stage / the boosting stage found\n",
      "        by using `early_stopping_rounds` is also printed.\n",
      "    xgb_model :\n",
      "        file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      "        loaded before training (allows training continuation).\n",
      "    sample_weight_eval_set :\n",
      "        A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      "        object storing instance weights for the i-th validation set.\n",
      "    base_margin_eval_set :\n",
      "        A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      "        object storing base margin for the i-th validation set.\n",
      "    feature_weights :\n",
      "        Weight for each feature, defines the probability of each feature being\n",
      "        selected when colsample is being used.  All values must be greater than 0,\n",
      "        otherwise a `ValueError` is thrown.\n",
      "\n",
      "    callbacks :\n",
      "        .. deprecated:: 1.6.0\n",
      "            Use `callbacks` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"您当前使用的 XGBoost 版本是: {xgb.__version__}\")\n",
    "\n",
    "# 创建一个临时的 XGBRegressor 实例，以便查看其 fit 方法的帮助文档\n",
    "temp_model = xgb.XGBRegressor()\n",
    "\n",
    "# 打印 fit 方法的帮助信息，这将显示它接受哪些参数\n",
    "help(temp_model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821aa08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始训练XGBoost回归模型...\n",
      "[0]\tvalidation_0-rmse:29.40647\tvalidation_1-rmse:29.18739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\tvalidation_0-rmse:26.16207\tvalidation_1-rmse:29.62095\n",
      "\n",
      "模型训练完成！\n",
      "验证集上的均方根误差 (RMSE): 29.1847\n",
      "模型在第 2 轮达到最佳。\n"
     ]
    }
   ],
   "source": [
    "if X_train_cv.shape[0] > 0 and X_val_cv.shape[0] > 0:\n",
    "    print(\"\\n开始训练XGBoost回归模型...\")\n",
    "\n",
    "    # 1. 定义早停回调\n",
    "    early_stopping_callback = xgb.callback.EarlyStopping(\n",
    "        rounds=50,\n",
    "        metric_name='rmse',\n",
    "        data_name='validation_1', # 对应 eval_set 中的第二个元素\n",
    "        save_best=True # 推荐开启，这样模型会自动是最佳状态\n",
    "    )\n",
    "\n",
    "    # 2. 初始化 XGBoost 回归器，并将 callbacks 传入构造函数\n",
    "    xgb_regressor_fixed = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='rmse',\n",
    "        tree_method='hist',\n",
    "        callbacks=[early_stopping_callback] # <--- callbacks 移到此处\n",
    "    )\n",
    "\n",
    "    # 3. 训练模型\n",
    "    # 注意：fit 方法中不再需要 callbacks 或 early_stopping_rounds 参数\n",
    "    xgb_regressor_fixed.fit(\n",
    "        X_train_cv,\n",
    "        y_train_cv,\n",
    "        eval_set=[(X_train_cv, y_train_cv), (X_val_cv, y_val_cv)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    print(\"\\n模型训练完成！\")\n",
    "\n",
    "    # 4. 在验证集上进行预测并评估\n",
    "    # 由于 save_best=True (在 EarlyStopping 回调中)，模型已经是最佳迭代次数的状态\n",
    "    y_pred_val = xgb_regressor_fixed.predict(X_val_cv)\n",
    "    \n",
    "    rmse_val = np.sqrt(mean_squared_error(y_val_cv, y_pred_val))\n",
    "    print(f\"验证集上的均方根误差 (RMSE): {rmse_val:.4f}\")\n",
    "    \n",
    "    # 获取最佳迭代次数\n",
    "    # 当使用 EarlyStopping 回调且 save_best=True 时，\n",
    "    # best_iteration 通常可以直接从模型对象获取，或者回调对象自身也会存储\n",
    "    if hasattr(xgb_regressor_fixed, 'best_iteration'):\n",
    "         print(f\"模型在第 {xgb_regressor_fixed.best_iteration +1 } 轮达到最佳。\")\n",
    "    elif hasattr(early_stopping_callback, 'best_iteration'): # 回调对象也可能存储\n",
    "         print(f\"模型在第 {early_stopping_callback.best_iteration + 1} 轮达到最佳。\")\n",
    "    else:\n",
    "        # 如果没有直接的 best_iteration 属性，\n",
    "        # 可以通过 xgb_regressor_fixed.get_booster().best_iteration 获取\n",
    "        # 但这取决于具体的XGBoost版本和回调实现细节\n",
    "        try:\n",
    "            print(f\"模型在第 {xgb_regressor_fixed.get_booster().best_iteration + 1} 轮达到最佳。\")\n",
    "        except Exception:\n",
    "            print(\"模型已根据早停规则训练至最佳状态 (具体轮数需从日志或回调中确认)。\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"错误：训练集 (X_train_cv) 或验证集 (X_val_cv) 为空，无法训练模型。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
